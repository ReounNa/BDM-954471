{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-29T10:44:05.517758Z","iopub.execute_input":"2021-08-29T10:44:05.518192Z","iopub.status.idle":"2021-08-29T10:44:05.529031Z","shell.execute_reply.started":"2021-08-29T10:44:05.518099Z","shell.execute_reply":"2021-08-29T10:44:05.528232Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('https://raw.githubusercontent.com/plenoi/Clinic/master/ultima_all_clean.csv')\ndf = df.set_index('hn')\n#df.head() # จะโชว์แค่5อัน\ndf","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:44:05.530138Z","iopub.execute_input":"2021-08-29T10:44:05.530565Z","iopub.status.idle":"2021-08-29T10:44:05.879136Z","shell.execute_reply.started":"2021-08-29T10:44:05.530528Z","shell.execute_reply":"2021-08-29T10:44:05.878193Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"         age  parity  hiv  menopaus  disease  surgery  conization  OPDsize  \\\nhn                                                                           \n2631840   52       3  0.0       0.0        1        1         0.0      5.0   \n2633481   32       2  0.0       0.0        0        1         0.0      5.0   \n2634477   52       2  0.0       0.0        0        0         0.0      5.0   \n2633633   38       2  0.0       0.0        0        0         0.0      2.0   \n2630496   55       3  0.0       1.0        0        0         1.0      0.0   \n...      ...     ...  ...       ...      ...      ...         ...      ...   \n3169688   47       2  0.0       0.0        0        0         1.0      0.0   \n3167041   39       1  0.0       0.0        0        0         1.0      0.0   \n2623351   46       2  0.0       0.0        0        0         1.0      0.0   \n3302539   44       3  0.0       0.0        0        1         1.0      0.0   \n3855674   38       2  0.0       0.0        0        0         0.0      3.0   \n\n         appearance  stage  ...  nodeyiel  RHlvsi  depth  size  utmet  \\\nhn                          ...                                         \n2631840         4.0    5.0  ...      21.0     0.0    3.0   6.0    0.0   \n2633481         1.0    5.0  ...      11.0     0.0    3.0   5.0    0.0   \n2634477         NaN    5.0  ...      35.0     6.0    3.0   4.0    0.0   \n2633633         1.0    4.0  ...      20.0    16.0    3.0   3.8    0.0   \n2630496         5.0    4.0  ...      17.0     9.0    3.0   0.0    0.0   \n...             ...    ...  ...       ...     ...    ...   ...    ...   \n3169688         5.0    4.0  ...      42.0     5.0    2.0   1.1    0.0   \n3167041         5.0    2.0  ...      20.0     0.0    NaN   0.0    0.0   \n2623351         5.0    1.0  ...      13.0     NaN    NaN   0.0    0.0   \n3302539         5.0    4.0  ...      15.0     NaN    NaN   0.0    0.0   \n3855674         4.0    4.0  ...      21.0   999.0    3.0   2.5    0.0   \n\n         vgmargin  vgmet  pelvicme  pmmet  adnmet  \nhn                                                 \n2631840       0.0    0.0       0.0    0.0     0.0  \n2633481       0.0    0.0       1.0    0.0     2.0  \n2634477       0.0    0.0       0.0    0.0     0.0  \n2633633       0.0    0.0       0.0    0.0     2.0  \n2630496       0.0    0.0       1.0    0.0     0.0  \n...           ...    ...       ...    ...     ...  \n3169688       0.0    0.0       0.0    0.0     2.0  \n3167041       0.0    0.0       0.0    0.0     2.0  \n2623351       0.0    0.0       0.0    0.0     0.0  \n3302539       0.0    0.0       0.0    0.0     0.0  \n3855674       2.0    1.0       1.0    1.0     0.0  \n\n[1723 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>parity</th>\n      <th>hiv</th>\n      <th>menopaus</th>\n      <th>disease</th>\n      <th>surgery</th>\n      <th>conization</th>\n      <th>OPDsize</th>\n      <th>appearance</th>\n      <th>stage</th>\n      <th>...</th>\n      <th>nodeyiel</th>\n      <th>RHlvsi</th>\n      <th>depth</th>\n      <th>size</th>\n      <th>utmet</th>\n      <th>vgmargin</th>\n      <th>vgmet</th>\n      <th>pelvicme</th>\n      <th>pmmet</th>\n      <th>adnmet</th>\n    </tr>\n    <tr>\n      <th>hn</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2631840</th>\n      <td>52</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2633481</th>\n      <td>32</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2634477</th>\n      <td>52</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>35.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2633633</th>\n      <td>38</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>20.0</td>\n      <td>16.0</td>\n      <td>3.0</td>\n      <td>3.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2630496</th>\n      <td>55</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>17.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3169688</th>\n      <td>47</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>42.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>1.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3167041</th>\n      <td>39</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2623351</th>\n      <td>46</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3302539</th>\n      <td>44</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3855674</th>\n      <td>38</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>21.0</td>\n      <td>999.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1723 rows × 23 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_clean_column = df.drop(['size','appearance','Wardsize','RHlvsi','depth','nodeyiel','vgmargin','pelvicme','adnmet'],axis = 1)\ndf_clean_column.isnull().sum(axis=0)\n# size กับ OPDsize หมอบอกคืออันเดียวกันเพราะงั้นลบซักอัน\n# 0 row / 1 column","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:44:21.687015Z","iopub.execute_input":"2021-08-29T10:44:21.687364Z","iopub.status.idle":"2021-08-29T10:44:21.697332Z","shell.execute_reply.started":"2021-08-29T10:44:21.687332Z","shell.execute_reply":"2021-08-29T10:44:21.696522Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"age            0\nparity         0\nhiv            4\nmenopaus       1\ndisease        0\nsurgery        0\nconization     5\nOPDsize       17\nstage         24\npchemo         1\nfinalhisto    10\nutmet         98\nvgmet         97\npmmet         94\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_clean = df_clean_column.dropna(axis = 0)\n#แถวไหนมี missing data ดรอบไป","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:44:30.576011Z","iopub.execute_input":"2021-08-29T10:44:30.576335Z","iopub.status.idle":"2021-08-29T10:44:30.598943Z","shell.execute_reply.started":"2021-08-29T10:44:30.576307Z","shell.execute_reply":"2021-08-29T10:44:30.598012Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"pel_class = np.unique(df_clean['pmmet'])\n#pel_class = df_clean['pmmet'].unique()\npel_class","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:44:56.565578Z","iopub.execute_input":"2021-08-29T10:44:56.565948Z","iopub.status.idle":"2021-08-29T10:44:56.573125Z","shell.execute_reply.started":"2021-08-29T10:44:56.565918Z","shell.execute_reply":"2021-08-29T10:44:56.572213Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([0., 1.])"},"metadata":{}}]},{"cell_type":"code","source":"pel_value = [sum(df_clean['pmmet']==pel_class[0]),\n             sum(df_clean['pmmet']==pel_class[1])]\npel_value","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:45:03.025376Z","iopub.execute_input":"2021-08-29T10:45:03.025714Z","iopub.status.idle":"2021-08-29T10:45:03.033019Z","shell.execute_reply.started":"2021-08-29T10:45:03.025686Z","shell.execute_reply":"2021-08-29T10:45:03.032221Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[1291, 280]"},"metadata":{}}]},{"cell_type":"code","source":"# เราจะเอา ค่า pmmet มาเป็นคำตอบของ model ดังนั้นเลยเก็บค่าไว้ใ้ช้\ny = df_clean['pmmet'].values # คำตอบ\nX = df_clean.drop(['pmmet'],axis = 1).values # ข้อมูล","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:45:17.645195Z","iopub.execute_input":"2021-08-29T10:45:17.645717Z","iopub.status.idle":"2021-08-29T10:45:17.650933Z","shell.execute_reply.started":"2021-08-29T10:45:17.645682Z","shell.execute_reply":"2021-08-29T10:45:17.650256Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"---------------","metadata":{}},{"cell_type":"markdown","source":"# HOLD OUT","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0) ","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:47:03.616744Z","iopub.execute_input":"2021-08-29T10:47:03.617245Z","iopub.status.idle":"2021-08-29T10:47:03.622284Z","shell.execute_reply.started":"2021-08-29T10:47:03.617212Z","shell.execute_reply":"2021-08-29T10:47:03.621403Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=0) ","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:47:05.255111Z","iopub.execute_input":"2021-08-29T10:47:05.255462Z","iopub.status.idle":"2021-08-29T10:47:05.261918Z","shell.execute_reply.started":"2021-08-29T10:47:05.255430Z","shell.execute_reply":"2021-08-29T10:47:05.260305Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# normalization\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1)) \nscaler.fit(X_train) \nX_train_norm = scaler.transform(X_train)\nX_val_norm = scaler.transform(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:48:28.968106Z","iopub.execute_input":"2021-08-29T10:48:28.968463Z","iopub.status.idle":"2021-08-29T10:48:28.974839Z","shell.execute_reply.started":"2021-08-29T10:48:28.968428Z","shell.execute_reply":"2021-08-29T10:48:28.973846Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(random_state=0, solver='liblinear')\nclf.fit(X_train_norm, y_train)\nyp = clf.predict(X_val_norm)\nacc = sum(yp == y_val)/len(y_val)\nprint(\"HOLD OUT Trainging accuracy : \"+str(acc))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:48:01.258230Z","iopub.execute_input":"2021-08-29T10:48:01.258724Z","iopub.status.idle":"2021-08-29T10:48:01.516803Z","shell.execute_reply.started":"2021-08-29T10:48:01.258677Z","shell.execute_reply":"2021-08-29T10:48:01.515751Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"HOLD OUT Trainging accuracy : 0.8174603174603174\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****จะทำtest ให้เอาตัว training dataทั้งหมดมาสร้าง modelอีกรอบ แล้วเอาไปtest****","metadata":{}},{"cell_type":"markdown","source":"---------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"markdown","source":"|| Leave One Out","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:49:37.895490Z","iopub.execute_input":"2021-08-29T10:49:37.895871Z","iopub.status.idle":"2021-08-29T10:49:37.904641Z","shell.execute_reply.started":"2021-08-29T10:49:37.895826Z","shell.execute_reply":"2021-08-29T10:49:37.903588Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# normalization\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1)) \nscaler.fit(X_train) \nX_train_norm = scaler.transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:49:39.358962Z","iopub.execute_input":"2021-08-29T10:49:39.359489Z","iopub.status.idle":"2021-08-29T10:49:39.365107Z","shell.execute_reply.started":"2021-08-29T10:49:39.359456Z","shell.execute_reply":"2021-08-29T10:49:39.364207Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nclf = LogisticRegression(random_state=0, solver='liblinear')\nacc = cross_val_score(clf,X_train_norm,y_train,cv=10) #ถ้าจะทำ--Leave One Out-- Cross Validation คือปรับ cv ให้เท่ากับขนาดข้อมูลทั้งหมด\nprint(\"10CV Training accuracy : \"+str(acc))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:49:40.827945Z","iopub.execute_input":"2021-08-29T10:49:40.828521Z","iopub.status.idle":"2021-08-29T10:49:40.879887Z","shell.execute_reply.started":"2021-08-29T10:49:40.828488Z","shell.execute_reply":"2021-08-29T10:49:40.878825Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"10CV Training accuracy : [0.81746032 0.80952381 0.81746032 0.78571429 0.81746032 0.81746032\n 0.8        0.832      0.816      0.824     ]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"10CV Training accuracy : \"+str(acc.mean()))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T10:49:42.487070Z","iopub.execute_input":"2021-08-29T10:49:42.487568Z","iopub.status.idle":"2021-08-29T10:49:42.493002Z","shell.execute_reply.started":"2021-08-29T10:49:42.487529Z","shell.execute_reply":"2021-08-29T10:49:42.491899Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"10CV Training accuracy : 0.8137079365079366\n","output_type":"stream"}]},{"cell_type":"markdown","source":"----------------------------","metadata":{}},{"cell_type":"markdown","source":"# Test accuracy","metadata":{}},{"cell_type":"markdown","source":"ของ data ใน *train ของ Hold out และ CV","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:14:40.068896Z","iopub.execute_input":"2021-08-29T11:14:40.069312Z","iopub.status.idle":"2021-08-29T11:14:40.076932Z","shell.execute_reply.started":"2021-08-29T11:14:40.069278Z","shell.execute_reply":"2021-08-29T11:14:40.075750Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# normali X_train_norm, X_test_norm\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1)) \nscaler.fit(X_train) \nX_train_norm = scaler.transform(X_train)\nX_test_norm = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:14:41.410214Z","iopub.execute_input":"2021-08-29T11:14:41.410739Z","iopub.status.idle":"2021-08-29T11:14:41.417272Z","shell.execute_reply.started":"2021-08-29T11:14:41.410697Z","shell.execute_reply":"2021-08-29T11:14:41.416344Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#model\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(random_state=0, solver='liblinear')\nclf.fit(X_train_norm, y_train)\nyp = clf.predict(X_test_norm) # X_test_norm\nacc = sum(yp == y_test)/len(y_test)\nprint(\"Test accuracy : \"+str(acc))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:15:39.124803Z","iopub.execute_input":"2021-08-29T11:15:39.125391Z","iopub.status.idle":"2021-08-29T11:15:39.137023Z","shell.execute_reply.started":"2021-08-29T11:15:39.125346Z","shell.execute_reply":"2021-08-29T11:15:39.135842Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Test accuracy : 0.8761904761904762\n","output_type":"stream"}]},{"cell_type":"markdown","source":"-----------------\n**HOLD OUT** Trainging accuracy : 0.817 <br>\n**10CV** Training accuracy : 0.813  <br><br>\n\n**Test accuracy** : 0.8761904761904762<br>\n","metadata":{}},{"cell_type":"markdown","source":"-------------------------\n","metadata":{}},{"cell_type":"markdown","source":"pre processing ที่ควรทำ (เพิ่มจากweekเก่า)","metadata":{}},{"cell_type":"code","source":"df.var(axis=0) # 0 คือ คอลลัม\n# hiv  0.006936 แปลว่า ไม่ว่ามันจะอยู่กลุ่มไหนค่ามันก็จะเป็นแค่ค่าเดียว ค่าเดิม (เหมือนๆกันหมดทุกโรล) เอาไปเปรียบเทียบกับกลุ่มอื่นๆไมไ่ด้","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:22:32.754857Z","iopub.execute_input":"2021-08-29T11:22:32.755285Z","iopub.status.idle":"2021-08-29T11:22:32.764561Z","shell.execute_reply.started":"2021-08-29T11:22:32.755251Z","shell.execute_reply":"2021-08-29T11:22:32.763705Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"age               81.065940\nparity             1.795348\nhiv                0.006936\nmenopaus           0.207860\ndisease            0.215740\nsurgery            0.234638\nconization         0.226518\nOPDsize            3.664245\nappearance         2.997285\nstage              1.383333\npchemo             0.149920\nWardsize           3.361144\nfinalhisto         0.744274\nnodeyiel         114.208070\nRHlvsi        231725.557678\ndepth              0.509143\nsize               3.207926\nutmet              0.153174\nvgmargin           0.189784\nvgmet              0.357326\npelvicme           0.388821\npmmet              0.146025\nadnmet             0.732903\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"df['hiv'] # เท่ากับ0 เป็นค่าคงที่ เอาออกเลย ไม่มีประโยชน์ในการทำ","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:22:39.922271Z","iopub.execute_input":"2021-08-29T11:22:39.922746Z","iopub.status.idle":"2021-08-29T11:22:39.930629Z","shell.execute_reply.started":"2021-08-29T11:22:39.922715Z","shell.execute_reply":"2021-08-29T11:22:39.929530Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"hn\n2631840    0.0\n2633481    0.0\n2634477    0.0\n2633633    0.0\n2630496    0.0\n          ... \n3169688    0.0\n3167041    0.0\n2623351    0.0\n3302539    0.0\n3855674    0.0\nName: hiv, Length: 1723, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"df.shape # ดูว่ามีข้อมูลเท่่าไหร่","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:27:10.800826Z","iopub.execute_input":"2021-08-29T11:27:10.801208Z","iopub.status.idle":"2021-08-29T11:27:10.807182Z","shell.execute_reply.started":"2021-08-29T11:27:10.801176Z","shell.execute_reply":"2021-08-29T11:27:10.806201Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(1723, 23)"},"metadata":{}}]},{"cell_type":"code","source":"# ดรอบ โรลข้อมูลซ้่ำ\ndf_nodup = df.drop_duplicates()\ndf_nodup.shape # ได้เท่าเดิม แปลว่าไม่มีข้อมูลซ้ำ","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:29:16.611512Z","iopub.execute_input":"2021-08-29T11:29:16.611838Z","iopub.status.idle":"2021-08-29T11:29:16.624274Z","shell.execute_reply.started":"2021-08-29T11:29:16.611811Z","shell.execute_reply":"2021-08-29T11:29:16.623240Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(1723, 23)"},"metadata":{}}]},{"cell_type":"code","source":"# หา correlation ขเ้อมูลที่คล้ายกันมากๆ ยิ่งใกล้1ยิ่งคล้าย\ns = df.corr().unstack()\nso = s.sort_values(ascending=False)\nso[0:50]\n# OPDsize  Wardsize  0.875699 ยังถือว่า โอเค แต่ถ้า 0.97-0.98 เราต้องไปถามละว่ามันคืออันเดียวกันไหม มันซ้ำซ้อนกันรึเปล่า ถ้าซ้ำก็เอาออก\n\n#  ถ้า training acc ูสูงเกิน 95% ให้คิดเลยว่าต้องมีอะไรผิด    \n#  หลักๆเลยคือ ให้ไปดู correlation ระว่าง feature กะับ label ถ้าเข้าใกล้ 1 **แสดงว่า feature นั้นคือ label **แต่เราเอามาเป็น feature","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:40:21.444667Z","iopub.execute_input":"2021-08-29T11:40:21.445005Z","iopub.status.idle":"2021-08-29T11:40:21.461500Z","shell.execute_reply.started":"2021-08-29T11:40:21.444959Z","shell.execute_reply":"2021-08-29T11:40:21.460371Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"age         age           1.000000\nfinalhisto  finalhisto    1.000000\nmenopaus    menopaus      1.000000\ndisease     disease       1.000000\nsurgery     surgery       1.000000\nconization  conization    1.000000\nOPDsize     OPDsize       1.000000\nappearance  appearance    1.000000\nstage       stage         1.000000\npchemo      pchemo        1.000000\nnodeyiel    nodeyiel      1.000000\nparity      parity        1.000000\nRHlvsi      RHlvsi        1.000000\ndepth       depth         1.000000\nsize        size          1.000000\nutmet       utmet         1.000000\nvgmargin    vgmargin      1.000000\nvgmet       vgmet         1.000000\npelvicme    pelvicme      1.000000\npmmet       pmmet         1.000000\nhiv         hiv           1.000000\nWardsize    Wardsize      1.000000\nadnmet      adnmet        1.000000\nOPDsize     Wardsize      0.875699\nWardsize    OPDsize       0.875699\nsize        Wardsize      0.804733\nWardsize    size          0.804733\nappearance  conization    0.794773\nconization  appearance    0.794773\nage         menopaus      0.721046\nmenopaus    age           0.721046\nOPDsize     size          0.717119\nsize        OPDsize       0.717119\nOPDsize     stage         0.593974\nstage       OPDsize       0.593974\nWardsize    stage         0.561104\nstage       Wardsize      0.561104\nsize        stage         0.505345\nstage       size          0.505345\nvgmet       vgmargin      0.500983\nvgmargin    vgmet         0.500983\ndepth       size          0.450857\nsize        depth         0.450857\n            pmmet         0.398485\npmmet       size          0.398485\npchemo      OPDsize       0.372687\nOPDsize     pchemo        0.372687\ndepth       Wardsize      0.339828\nWardsize    depth         0.339828\ndisease     age           0.323504\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"so[20:30]","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:32:57.767898Z","iopub.execute_input":"2021-08-29T11:32:57.768290Z","iopub.status.idle":"2021-08-29T11:32:57.774908Z","shell.execute_reply.started":"2021-08-29T11:32:57.768259Z","shell.execute_reply":"2021-08-29T11:32:57.774160Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"hiv         hiv           1.000000\nWardsize    Wardsize      1.000000\nadnmet      adnmet        1.000000\nOPDsize     Wardsize      0.875699\nWardsize    OPDsize       0.875699\nsize        Wardsize      0.804733\nWardsize    size          0.804733\nappearance  conization    0.794773\nconization  appearance    0.794773\nage         menopaus      0.721046\ndtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"-----------------\n\n# Feature Reduction","metadata":{}},{"cell_type":"markdown","source":"ไม่แนะนำให้ยุบ เพราะ เวลายุบ ความหมายจะ หาย ทำให้ตอบไม่ได้ว่าfeatureตัวไหนมีผลกับการหาค่า <br>\nทำแล้วโมเดลอาจแม่นขึ้น แต่ส่วนใหญ่แม่นน้อยลง","metadata":{}},{"cell_type":"markdown","source":"# PCA - Principle Component Analysis","metadata":{}},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:58:14.249171Z","iopub.execute_input":"2021-08-29T11:58:14.249508Z","iopub.status.idle":"2021-08-29T11:58:14.258592Z","shell.execute_reply.started":"2021-08-29T11:58:14.249480Z","shell.execute_reply":"2021-08-29T11:58:14.257781Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(1256, 13)"},"metadata":{}}]},{"cell_type":"code","source":"# ปกติมักทำก่อน normalization\nfrom sklearn.decomposition import PCA\npca = PCA(n_components = 5) # ลดFeatureจาก13 ให้เหลือ5\npca.fit(X_train)\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\n\n# normalization\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler.fit(X_train_pca)\nX_train_norm = scaler.transform(X_train_pca)\nX_test_norm = scaler.transform(X_test_pca)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:58:36.686364Z","iopub.execute_input":"2021-08-29T11:58:36.686913Z","iopub.status.idle":"2021-08-29T11:58:36.697043Z","shell.execute_reply.started":"2021-08-29T11:58:36.686880Z","shell.execute_reply":"2021-08-29T11:58:36.696081Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(random_state=0, solver='liblinear')\nclf.fit(X_train_norm, y_train)\nyp = clf.predict(X_test_norm)\nacc = sum(yp == y_test)/len(y_test)\nprint(\"Test accuracy : \"+str(acc))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T11:58:40.034521Z","iopub.execute_input":"2021-08-29T11:58:40.035137Z","iopub.status.idle":"2021-08-29T11:58:40.045529Z","shell.execute_reply.started":"2021-08-29T11:58:40.035101Z","shell.execute_reply":"2021-08-29T11:58:40.044360Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Test accuracy : 0.8507936507936508\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# t-SNE ","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components = 2)\ntsne.fit(X_train)\nX_train_tsne = tsne.fit_transform(X_train)\nX_test_tsne = tsne.fit_transform(X_test)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler.fit(X_train_tsne)\nX_train_norm = scaler.transform(X_train_tsne)\nX_test_norm = scaler.transform(X_test_tsne)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T12:04:33.108027Z","iopub.execute_input":"2021-08-29T12:04:33.108373Z","iopub.status.idle":"2021-08-29T12:04:45.976136Z","shell.execute_reply.started":"2021-08-29T12:04:33.108344Z","shell.execute_reply":"2021-08-29T12:04:45.975255Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(random_state=0, solver='liblinear')\nclf.fit(X_train_norm, y_train)\nyp = clf.predict(X_test_norm)\nacc = sum(yp == y_test)/len(y_test)\nprint(\"Test accuracy : \"+str(acc))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T12:04:49.482459Z","iopub.execute_input":"2021-08-29T12:04:49.483094Z","iopub.status.idle":"2021-08-29T12:04:49.492661Z","shell.execute_reply.started":"2021-08-29T12:04:49.483057Z","shell.execute_reply":"2021-08-29T12:04:49.491620Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Test accuracy : 0.8507936507936508\n","output_type":"stream"}]},{"cell_type":"markdown","source":"-----------------------\n# Feature Selection <br>สำคัญมาก","metadata":{}},{"cell_type":"markdown","source":"เลือก Feature ที่มีความสำคัญมากๆ มาใช้ ","metadata":{}},{"cell_type":"markdown","source":"# Filter Method\n#  SelectKBest || Filter Method || ANOVA f-value","metadata":{}},{"cell_type":"code","source":"#feature_selection\nfrom sklearn.feature_selection import SelectKBest # SelectKBest เลือก Feature ที่ดีที่สุดตามค่า ที่เราสนใจออกมา K ตัว\nfrom sklearn.feature_selection import f_classif   # ANOVA f-value\nfs = SelectKBest(f_classif, k=5)\nfs.fit(X_train, y_train)\nX_train_fs = fs.transform(X_train)\nX_test_fs = fs.transform(X_test)\n\n# normalization\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler.fit(X_train_fs)\nX_train_norm = scaler.transform(X_train_fs)\nX_test_norm = scaler.transform(X_test_fs)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T12:23:59.540078Z","iopub.execute_input":"2021-08-29T12:23:59.540413Z","iopub.status.idle":"2021-08-29T12:23:59.548608Z","shell.execute_reply.started":"2021-08-29T12:23:59.540387Z","shell.execute_reply":"2021-08-29T12:23:59.547842Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# ดูว่าเลือก Feature อะไรมาบ้าง\n\nnp.argsort(-fs.scores_)\n\n# ก็คือเอาคะแนนมากที่สุดมา 5 ตัว ดูโดยเรียงจากมากไปน้อย จะ ได้ Feature 7,  8, 11,  6, 12","metadata":{"execution":{"iopub.status.busy":"2021-08-29T12:20:20.126176Z","iopub.execute_input":"2021-08-29T12:20:20.126523Z","iopub.status.idle":"2021-08-29T12:20:20.132773Z","shell.execute_reply.started":"2021-08-29T12:20:20.126494Z","shell.execute_reply":"2021-08-29T12:20:20.131766Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"array([ 7,  8, 11,  6, 12,  3,  0, 10,  4,  9,  5,  2,  1])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(random_state=0, solver='liblinear')\nclf.fit(X_train_norm, y_train)\nyp = clf.predict(X_test_norm)\nacc = sum(yp == y_test)/len(y_test)\nprint(\"Test accuracy : \"+str(acc))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T12:19:27.425753Z","iopub.execute_input":"2021-08-29T12:19:27.426108Z","iopub.status.idle":"2021-08-29T12:19:27.436128Z","shell.execute_reply.started":"2021-08-29T12:19:27.426075Z","shell.execute_reply":"2021-08-29T12:19:27.435130Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Test accuracy : 0.8603174603174604\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Wrapper Method\nsklearn v.ไม่ถึง ต้องอัพเป็น 0.2.4 + ยังไม่มีfunctionในสื่อการสอน รอก่อน","metadata":{}},{"cell_type":"markdown","source":"# Embedded Method\nEx. Random forest","metadata":{}},{"cell_type":"markdown","source":"----------------","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=1)\nX_res, y_res = sm.fit_resample(X_train, y_train)\n\nfrom sklearn.pipeline import Pipeline\nclf = Pipeline([\n  ('scaler', MinMaxScaler(feature_range=(0, 1))),\n  ('feature_selection', SelectKBest(f_classif, k=5)),\n  ('classification', LogisticRegression(random_state=0, solver='liblinear'))\n])\nclf.fit(X_res, y_res)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T12:45:54.118297Z","iopub.execute_input":"2021-08-29T12:45:54.118791Z","iopub.status.idle":"2021-08-29T12:45:54.328741Z","shell.execute_reply.started":"2021-08-29T12:45:54.118759Z","shell.execute_reply":"2021-08-29T12:45:54.327839Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('scaler', MinMaxScaler()),\n                ('feature_selection', SelectKBest(k=5)),\n                ('classification',\n                 LogisticRegression(random_state=0, solver='liblinear'))])"},"metadata":{}}]},{"cell_type":"code","source":"yp = clf.predict(X_test)\nacc = sum(yp == y_test)/len(y_test)\nprint(\"Test accuracy : \"+str(acc))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T12:45:56.119017Z","iopub.execute_input":"2021-08-29T12:45:56.119478Z","iopub.status.idle":"2021-08-29T12:45:56.127211Z","shell.execute_reply.started":"2021-08-29T12:45:56.119448Z","shell.execute_reply":"2021-08-29T12:45:56.126112Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Test accuracy : 0.765079365079365\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Assignment","metadata":{}},{"cell_type":"markdown","source":"# Feature Reduction + Feature Selection + Imbalance + Pipeline ","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=1)\nX_res, y_res = sm.fit_resample(X_train, y_train)\n\nparams = {\n    'C' : [0.1,1,10],\n    'gamma' : [0.0001,0.002,0.04,0.8,1.8,3.2,5,10],\n    'break_ties' : ['True']\n}\n\nfrom sklearn.pipeline import Pipeline\nclf = Pipeline([\n  ('scaler', MinMaxScaler(feature_range=(0, 1))),\n  ('feature_selection', SelectKBest(f_classif, k=5)),\n  ('classification', GridSearchCV(SVC(random_state=0),params, cv = 10))\n])\nclf.fit(X_res, y_res)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T13:05:55.935565Z","iopub.execute_input":"2021-08-29T13:05:55.935915Z","iopub.status.idle":"2021-08-29T13:06:24.816079Z","shell.execute_reply.started":"2021-08-29T13:05:55.935886Z","shell.execute_reply":"2021-08-29T13:06:24.814972Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('scaler', MinMaxScaler()),\n                ('feature_selection', SelectKBest(k=5)),\n                ('classification',\n                 GridSearchCV(cv=10, estimator=SVC(random_state=0),\n                              param_grid={'C': [0.1, 1, 10],\n                                          'break_ties': ['True'],\n                                          'gamma': [0.0001, 0.002, 0.04, 0.8,\n                                                    1.8, 3.2, 5, 10]}))])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nacc = cross_val_score(clf, X_res, y_res, cv=10)\nprint(\"10CV Training Accuracy : \"+str(acc.mean()))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T13:06:27.783374Z","iopub.execute_input":"2021-08-29T13:06:27.783694Z","iopub.status.idle":"2021-08-29T13:10:21.897476Z","shell.execute_reply.started":"2021-08-29T13:06:27.783667Z","shell.execute_reply":"2021-08-29T13:10:21.896285Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"10CV Training Accuracy : 0.7860090865614537\n","output_type":"stream"}]},{"cell_type":"code","source":"yp = clf.predict(X_test)\nacc = sum(yp == y_test)/len(y_test)\nprint(\"Test accuracy : \"+str(acc))","metadata":{"execution":{"iopub.status.busy":"2021-08-29T13:10:38.505694Z","iopub.execute_input":"2021-08-29T13:10:38.506056Z","iopub.status.idle":"2021-08-29T13:10:38.522340Z","shell.execute_reply.started":"2021-08-29T13:10:38.506025Z","shell.execute_reply":"2021-08-29T13:10:38.521099Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Test accuracy : 0.8666666666666667\n","output_type":"stream"}]}]}